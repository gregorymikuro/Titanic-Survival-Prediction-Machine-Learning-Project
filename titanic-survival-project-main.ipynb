{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Titanic Survival Prediction Machine Learning Project - Gregory Mikuro__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __1.0 Business Understanding__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1.1 Background and Problem Statement__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic on April 15, 1912, stands as one of the most tragic maritime disasters in history. The \"unsinkable\" ship met its fate after colliding with an iceberg, leading to the loss of 1502 lives out of the 2224 passengers and crew onboard. The limited number of lifeboats meant that survival was not guaranteed for everyone.\n",
    "\n",
    "Analysis of the incident suggests that certain groups of people had a higher likelihood of survival than others. This challenge aims to leverage passenger data to unravel the factors that influenced survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1.2 Business Objectives__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary objective of this project is to develop a predictive model that can accurately identify the characteristics or profiles of passengers who were more likely to survive the Titanic disaster. By understanding these patterns, we can gain valuable insights into the social, economic, and demographic factors that played a role in survival during this historic event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1.3 Data Mining Goals__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve this objective, the following data mining goals are defined:\n",
    "\n",
    "1. Data Exploration and Preparation: Thoroughly analyze and preprocess the passenger dataset, addressing missing values, outliers, and inconsistencies.\n",
    "2. Feature Engineering: Create relevant features from existing data to enhance the model's predictive power (e.g., family size, social group affiliations).\n",
    "3. Model Selection and Training: Evaluate various machine learning algorithms (e.g., logistic regression, random forest) to identify the most suitable model for predicting survival.\n",
    "4. Model Evaluation and Validation: Rigorously assess the chosen model's performance using appropriate metrics (e.g., accuracy, precision, recall) and validation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1.4 Business Success Criteria__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The success of this project will be measured by the following criteria:\n",
    "* Model Accuracy: The predictive model should achieve a high level of accuracy in classifying passengers as survivors or non-survivors.\n",
    "* Interpretability: The model's results should be easily interpretable, providing clear insights into the factors influencing survival.\n",
    "* Actionable Insights: The findings from this project should contribute to a deeper understanding of the Titanic disaster and potentially inform future safety measures in maritime travel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2.0 Data Understanding__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __2.1 Overview__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this analysis is divided into two distinct subsets: the training set (`train.csv`) and the test set (`test.csv`). The training set is designed for building machine learning models, providing both the input features and the outcome, or \"ground truth,\" for each passenger. These outcomes indicate whether each passenger survived the Titanic disaster, enabling the development and validation of predictive models. Key features in this dataset include passenger characteristics such as gender and class, among others. Feature engineering can be employed to create new variables that might enhance the model's predictive power.\n",
    "\n",
    "In contrast, the test set is used to evaluate the performance of the model on unseen data. The outcomes for the passengers in this set are not provided, and it is the model's task to predict these survival outcomes. A sample submission file, `gender_submission.csv`, is also provided. This file predicts survival based solely on gender, assuming all female passengers survived and no male passengers did. This serves as a baseline for what a submission file should look like and provides a rudimentary benchmark for model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __2.2 Data Dictionary__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "The variables in the dataset are defined as follows:\n",
    "\n",
    "| Variable  | Definition                                  | Key                                                   |\n",
    "|-----------|---------------------------------------------|-------------------------------------------------------|\n",
    "| survival  | Survival                                    | 0 = No, 1 = Yes                                       |\n",
    "| pclass    | Ticket class                                | 1 = 1st, 2 = 2nd, 3 = 3rd                             |\n",
    "| sex       | Sex                                         |                                                       |\n",
    "| age       | Age in years                                |                                                       |\n",
    "| sibsp     | Number of siblings/spouses aboard the Titanic |                                                       |\n",
    "| parch     | Number of parents/children aboard the Titanic |                                                       |\n",
    "| ticket    | Ticket number                               |                                                       |\n",
    "| fare      | Passenger fare                              |                                                       |\n",
    "| cabin     | Cabin number                                |                                                       |\n",
    "| embarked  | Port of Embarkation                         | C = Cherbourg, Q = Queenstown, S = Southampton        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __2.2 Variable Notes__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **pclass**: This variable serves as a proxy for socio-economic status (SES). The classes are defined as:\n",
    "  - 1st = Upper class\n",
    "  - 2nd = Middle class\n",
    "  - 3rd = Lower class\n",
    "\n",
    "- **age**: The age variable is fractional for ages less than one year. If the age is estimated, it is presented in the form of xx.5.\n",
    "\n",
    "- **sibsp**: This variable counts the number of siblings and spouses aboard the Titanic. The dataset defines family relations as:\n",
    "  - Sibling = brother, sister, stepbrother, stepsister\n",
    "  - Spouse = husband, wife (excluding mistresses and fianc√©s)\n",
    "\n",
    "- **parch**: This variable counts the number of parents and children aboard the Titanic. Family relations are defined as:\n",
    "  - Parent = mother, father\n",
    "  - Child = daughter, son, stepdaughter, stepson\n",
    "\n",
    "- Some children traveled only with a nanny; in these cases, `parch` is set to 0.\n",
    "\n",
    "The clear delineation and definitions of these variables are crucial for the accurate construction and interpretation of predictive models. Understanding the nuances of these variables helps in the application of appropriate feature engineering techniques, thereby potentially improving the model's performance in predicting the survival of passengers on the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __3.0 Data Preparation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __3.1 Import Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import nbimporter\n",
    "# import titanic_survival_project_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __3.2 Data Overview__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an extractor class with instances of importing the train and test data from data/test.csv and data/train.csv, and gives summary of statistics, describe, info, percentage of missing values of the data etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataExtractor:\n",
    "    def __init__(self, train_path, test_path):\n",
    "        self.train_data = pd.read_csv(train_path)\n",
    "        self.test_data = pd.read_csv(test_path)\n",
    "\n",
    "    def summary_statistics(self, data):\n",
    "        print(\"\\n--- Summary Statistics ---\")\n",
    "        print(data.describe().to_markdown(numalign='left', stralign='left'))\n",
    "\n",
    "    def describe(self, data):\n",
    "        print(\"\\n--- Data Description ---\")\n",
    "        print(data.describe(include='all').to_markdown(numalign='left', stralign='left'))\n",
    "\n",
    "    def info(self, data):\n",
    "        print(\"\\n--- Data Information ---\")\n",
    "        print(data.info())\n",
    "\n",
    "    def missing_percentage(self, data):\n",
    "        print(\"\\n--- Missing Values Percentage ---\")\n",
    "        missing_percent = (data.isnull().sum() / len(data)) * 100\n",
    "        print(missing_percent.to_markdown(numalign='left', stralign='left'))\n",
    "\n",
    "\n",
    "# Example Usage (replace with your actual file paths)\n",
    "extractor = DataExtractor(\"data/train.csv\", \"data/test.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __3.2.1 Training Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train Data:\")\n",
    "# extractor.summary_statistics(extractor.train_data)\n",
    "# extractor.describe(extractor.train_data)\n",
    "# extractor.info(extractor.train_data)\n",
    "# extractor.missing_percentage(extractor.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__\n",
    "\n",
    "* Based on the analysis of the train dataset, three columns have missing values - Age, Cabin and Embarked \n",
    "* There are no duplicates\n",
    "* The unique values are accurate and appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __3.2.2 Test Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nTest Data:\")\n",
    "# extractor.summary_statistics(extractor.test_data)\n",
    "# extractor.describe(extractor.test_data)\n",
    "# extractor.info(extractor.test_data)\n",
    "# extractor.missing_percentage(extractor.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__\n",
    "\n",
    "* Based on the analysis of the test dataset, three columns have missing and null values - Age, Cabin and Fare \n",
    "* There are no duplicates\n",
    "* The unique values are accurate and appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Possible Strategy__\n",
    "1. Drop cabin columns for both datasets because of the large number of missing values\n",
    "2. Drop ticket columns for both datasets because of high number of unique values hence might not have prediction power\n",
    "3. For the missing values for both datasets fare, embarked and age with imputation \n",
    "4. Break name column to create new column column for 'title'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __3.3 Data Cleaning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "class DataCleaner(DataExtractor):\n",
    "    # ... (rest of the class code is the same)\n",
    "\n",
    "    def clean_data(self):\n",
    "        # Drop 'Cabin' and 'Ticket' columns\n",
    "        self.train_data = self.train_data.drop(['Cabin', 'Ticket'], axis=1)\n",
    "        self.test_data = self.test_data.drop(['Cabin', 'Ticket'], axis=1)\n",
    "\n",
    "        # Impute missing values (updated)\n",
    "        for df in [self.train_data, self.test_data]:\n",
    "            df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "            df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "            df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "        print(\"Data cleaning complete!\")\n",
    "\n",
    "\n",
    "cleaner = DataCleaner(\"data/train.csv\", \"data/test.csv\")\n",
    "cleaner.clean_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nCleaned Train Data:\")\n",
    "# cleaner.summary_statistics(cleaner.train_data)\n",
    "# cleaner.describe(cleaner.train_data)\n",
    "# cleaner.info(cleaner.train_data)\n",
    "# cleaner.missing_percentage(cleaner.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nCleaned Test Data:\")\n",
    "# cleaner.summary_statistics(cleaner.test_data)\n",
    "# cleaner.describe(cleaner.test_data)\n",
    "# cleaner.info(cleaner.test_data)\n",
    "# cleaner.missing_percentage(cleaner.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __3.4 Feature Engineering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer(DataCleaner):\n",
    "    def __init__(self, train_path, test_path):\n",
    "        super().__init__(train_path, test_path)\n",
    "\n",
    "    def engineer_features(self):\n",
    "        # Extract titles and create new 'Status' column\n",
    "        for df in [self.train_data, self.test_data]:\n",
    "            df['Status'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "            df.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "        print(\"Feature engineering complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete!\n",
      "Feature engineering complete!\n"
     ]
    }
   ],
   "source": [
    "engineer = FeatureEngineer(\"data/train.csv\", \"data/test.csv\")\n",
    "engineer.clean_data()  # Clean data first\n",
    "engineer.engineer_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nEngineered Train Data:\")\n",
    "# engineer.summary_statistics(engineer.train_data)\n",
    "# engineer.describe(engineer.train_data)\n",
    "# engineer.info(engineer.train_data)\n",
    "# engineer.missing_percentage(engineer.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nEngineered Test Data:\")\n",
    "# engineer.summary_statistics(engineer.test_data)\n",
    "# engineer.describe(engineer.test_data)\n",
    "# engineer.info(engineer.test_data)\n",
    "# engineer.missing_percentage(engineer.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __4.0 Exploratory Data Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __4.1 Univariate Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __4.2 Bivariate Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __4.3 Multivariate Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __5.0 Modeling__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __5.1 Data Preprocessing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __5.1.1 Encoding__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __5.1.2 Feature Selection__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __5.1.2.1 Correlation analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __5.1.2.2 Variance Inflation Factor (VIF)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __5.1.3 Log Transformation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __5.1.4 Scaling__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __5.1.5 Principal Component Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __6.0 Evaluation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __7.0 Deployment__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __8.0 Conclusion__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __9.0 Recommendation__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
